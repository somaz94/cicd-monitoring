---
replicas: 1

logstashConfig:
  logstash.yml: |
    http.host: 0.0.0.0
    xpack.monitoring.enabled: false

logstashPipeline:
  uptime.conf: |
    input { exec { command => "uptime" interval => 30 } }
    output {
      elasticsearch {
        hosts => ["https://elasticsearch-master:9200"]
        user => '${ELASTICSEARCH_USERNAME}'
        cacert => '/usr/share/logstash/config/certs/ca.crt'
        password => '${ELASTICSEARCH_PASSWORD}'
        index => "logstash-%{+YYYY.MM.dd}"    # 날짜별 인덱스 패턴
      }
      # Filebeat 로그를 파일로 저장
      file {
        path => "/usr/share/logstash/data/logs/filebeat-%{+YYYY-MM-dd}.log.gz"  # .gz 확장자 추가
        codec => json_lines
        create_if_deleted => true
        write_behavior => "append"
        gzip => true          # 로그 압축 활성화
      }
    }

# Allows you to add any pattern files in your custom pattern dir
logstashPatternDir: "/usr/share/logstash/patterns/"


extraEnvs:
  - name: ELASTICSEARCH_USERNAME
    valueFrom:
      secretKeyRef:
        name: elasticsearch-master-credentials
        key: username
  - name: ELASTICSEARCH_PASSWORD
    valueFrom:
      secretKeyRef:
        name: elasticsearch-master-credentials
        key: password

envFrom:
  - secretRef:
      name: elasticsearch-master-credentials

# Add sensitive data to k8s secrets
secrets: []
  # - name: "env"
  #   value:
  #     ELASTICSEARCH_USERNAME: "elastic"
  #     ELASTICSEARCH_PASSWORD: "concrit123!"

secretMounts:
  - name: elastic-certs
    secretName: elasticsearch-master-certs
    path: /usr/share/logstash/config/certs

image: "docker.elastic.co/logstash/logstash"
imageTag: "8.5.1"
imagePullPolicy: "IfNotPresent"
imagePullSecrets: []

logstashJavaOpts: "-Xmx1g -Xms1g"

resources:
  requests:
    cpu: "100m"
    memory: "1536Mi"
  limits:
    cpu: "1000m"
    memory: "1536Mi"

volumeClaimTemplate:
  accessModes: ["ReadWriteOnce"]
  storageClassName: nfs-client
  resources:
    requests:
      storage: 1Gi

rbac:
  create: true
  serviceAccountAnnotations: {}
  serviceAccountName: ""
  annotations:
    {}
    #annotation1: "value1"
    #annotation2: "value2"
    #annotation3: "value3"

persistence:
  enabled: true
  annotations:
    nfs.io/storage-path: "logstash"

# By default this will make sure two pods don't end up on the same node
# Changing this to a region would allow you to spread pods across regions
antiAffinityTopologyKey: "kubernetes.io/hostname"

# Hard means that by default pods will only be scheduled if there are enough nodes for them
# and that they will never end up on the same node. Setting this to soft will do this "best effort"
antiAffinity: "hard"

# The default is to deploy all pods serially. By setting this to parallel all pods are started at
# the same time when bootstrapping the cluster
podManagementPolicy: "Parallel"

httpPort: 9600

# Custom ports to add to logstash
extraPorts:
  []
  # - name: beats
  #   containerPort: 5001

updateStrategy: RollingUpdate

# This is the max unavailable setting for the pod disruption budget
# The default value of 1 will make sure that kubernetes won't allow more than 1
# of your pods to be unavailable during maintenance
maxUnavailable: 1

# How long to wait for logstash to stop gracefully
terminationGracePeriod: 120

service:
  annotations: {}
  type: ClusterIP
  loadBalancerIP: ""
  ports:
    - name: beats
      port: 5044
      protocol: TCP
      targetPort: 5044
    - name: http
      port: 8080
      protocol: TCP
      targetPort: 8080

ingress:
  enabled: false
  annotations:
    {}
    # kubernetes.io/tls-acme: "true"
  className: "nginx"
  pathtype: ImplementationSpecific
  hosts:
    - host: logstash-example.local
      paths:
        - path: /beats
          servicePort: 5044
        - path: /http
          servicePort: 8080
  tls: []
  #  - secretName: logstash-example-tls
  #    hosts:
  #      - logstash-example.local
