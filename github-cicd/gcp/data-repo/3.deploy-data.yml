# This workflow will do a clean installation of node dependencies, cache/restore them, build the source code and run tests across different versions of node
# For more information see: https://help.github.com/actions/language-and-framework-guides/using-nodejs-with-github-actions

name: 3.Data Deploy

on:
  workflow_dispatch:
  workflow_call:
    inputs:
      modifiedJsonFileNames:
        description: Modified json file names with double quoute and comma
        type: string
        required: true
      environment:
        description: Target Branch
        type: string
        required: true

jobs:
  # upload generated json to patch GCS(CDN)
  upload:
    name: Upload json to patch GCS
    runs-on: ubuntu-20.04

    # Add "id-token" with the intended permissions.
    permissions:
      contents: read
      id-token: write

    steps:
      - name: Check out branch
        uses: actions/checkout@v3

      - name: Configure GCP credentials
        id: auth         
        uses: google-github-actions/auth@v1
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}      

      # - name: Set secrets to gcs 
      #   uses: noliran/branch-based-secrets@v1
      #   with:
      #     # This action makes env which concatenated with ASP_PATCH_S3_BUCKET and Branch name.
      #     # So, we can find branch based secret dynamic.
      #     # example _) ASP_PATCH_S3_BUCKET_DEVELOP
      #     secrets: SM_CDN_GCS_BUCKET,GCP_ASP_PROJECT     

      - name: Set secrets to gcs 
        uses: noliran/branch-based-secrets@v1
        with:
          secrets: SM_CDN_GCS_BUCKET,GCP_SM_PROJECT,GCP_SM_CLOUDCDN_URL_MAP

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1

      # - name: Select Project
      #   env:
      #     GCP_ASP_PROJECT: ${{ secrets[env.GCP_ASP_PROJECT_NAME] }}
      #   run: |
      #     gcloud config set project ${{ env.GCP_ASP_PROJECT }}
      #     gcloud config configurations list

      - name: Select Project
        env:
          GCP_SM_PROJECT: ${{ secrets[env.GCP_SM_PROJECT_NAME] }}
        run: |
          gcloud config set project ${{ env.GCP_SM_PROJECT }}
          gcloud config configurations list

      - name: Set short sha
        id: vars
        # run: echo "::set-output name=short_sha::$(git rev-parse --short HEAD)"
        run: echo "short_sha=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT

      # You must register BOTO_CONFIG with GitHub Secret.
      # [GSUtil]
      # parallel_thread_count = 10
      # parallel_process_count = 5        
      - name: Set up gsutil configuration
        run: |
          echo "${{ secrets.BOTO_CONFIG }}" > ./.boto
          echo "GSUTIL_BOTO_CONFIG=./.boto" >> $GITHUB_ENV

      - name: Deploy to GCS
        if: github.ref_name != 'production'
        env:
          COMMIT_HASH: ${{ steps.vars.outputs.short_sha }}
          SM_CDN_GCS_BUCKET: ${{ secrets[env.SM_CDN_GCS_BUCKET_NAME] }}
        run: |
          gsutil -m rsync -d -r ./Convertor/ClientJson/ gs://${{ env.SM_CDN_GCS_BUCKET }}/${{ github.ref_name }}/data/asp/latest
          gsutil -m rsync -d -r ./Convertor/ClientJson/ gs://${{ env.SM_CDN_GCS_BUCKET }}/${{ github.ref_name }}/data/asp/${{ env.COMMIT_HASH }}

      - name: Deploy to GCS Production
        if: github.ref_name == 'production'
        env:
          COMMIT_HASH: ${{ steps.vars.outputs.short_sha }}
          SM_CDN_GCS_BUCKET: ${{ secrets[env.SM_CDN_GCS_BUCKET_NAME] }}
        run: |
          gsutil -m rsync -d -r ./Convertor/ClientJson/ gs://${{ env.SM_CDN_GCS_BUCKET }}/data/asp/latest
          gsutil -m rsync -d -r ./Convertor/ClientJson/ gs://${{ env.SM_CDN_GCS_BUCKET }}/data/asp/${{ env.COMMIT_HASH }}

      - name: Delete previous commit folders
        if: github.ref_name != 'production'
        env:
          COMMIT_HASH: ${{ steps.vars.outputs.short_sha }}
          SM_CDN_GCS_BUCKET: ${{ secrets[env.SM_CDN_GCS_BUCKET_NAME] }}
        run: |
          gsutil ls -d gs://${{ env.SM_CDN_GCS_BUCKET }}/${{ github.ref_name }}/data/asp/*/ | grep -E -v "/latest|/${{ env.COMMIT_HASH }}/" | xargs -I {} gsutil -m rm -r {}
          # gsutil ls gs://${{ env.SM_CDN_GCS_BUCKET }}/${{ github.ref_name }}/data/asp/ | grep -E -v "/latest|/${{ env.COMMIT_HASH }}/" | xargs -I {} gsutil -m rm -r {}

      - name: Delete previous commit folders Prodcution
        if: github.ref_name == 'production'
        env:
          COMMIT_HASH: ${{ steps.vars.outputs.short_sha }}
          SM_CDN_GCS_BUCKET: ${{ secrets[env.SM_CDN_GCS_BUCKET_NAME] }}
        run: |
          gsutil ls -d gs://${{ env.SM_CDN_GCS_BUCKET }}/data/asp/*/ | grep -v "/latest" | grep -v "/${{ env.COMMIT_HASH }}/"
          gsutil ls -d gs://${{ env.SM_CDN_GCS_BUCKET }}/data/asp/*/ | grep -v "/latest" | grep -v "/${{ env.COMMIT_HASH }}/" | xargs -I {} gsutil -m rm -r {}

      - name: Invalidate cache CloudFront
        if: github.ref_name != 'production'
        env:
          GCP_SM_PROJECT: ${{ secrets[env.GCP_SM_PROJECT_NAME] }}
        run: |
          echo "Invalidating cache for production environment..."
          gcloud compute url-maps list --project ${{ env.GCP_SM_PROJECT }}
          gcloud compute url-maps invalidate-cdn-cache ${{ secrets[env.GCP_SM_CLOUDCDN_URL_MAP_NAME] }} \
          --path "/${{ github.ref_name }}/data/asp/latest" \
          --global \
          --project ${{ env.GCP_SM_PROJECT }}

      - name: Invalidate cache CloudFront Proudction
        if: github.ref_name == 'production'
        env:
          GCP_SM_PROJECT: ${{ secrets[env.GCP_SM_PROJECT_NAME] }}        
        run: |
          echo "Invalidating cache for production environment..."
          gcloud compute url-maps list --project ${{ env.GCP_SM_PROJECT }}
          gcloud compute url-maps invalidate-cdn-cache ${{ secrets[env.GCP_SM_CLOUDCDN_URL_MAP_NAME] }} \
          --path "/data/asp/latest" \
          --global \
          --project ${{ env.GCP_SM_PROJECT }}

  # ASP 완전 삭제 시 전부 수정        
  # copy data files to ec2 using sftp
  rsync:
    name: Upload data to the gcp computer engine
    runs-on: ubuntu-20.04
    env:
      PROJECT: asp
    steps:
      - name: Check out branch
        uses: actions/checkout@v2
        with:
          ref: ${{ github.event.workflow_run.head_branch }}

      # - name: Set secrets
      #   uses: noliran/branch-based-secrets@v1
      #   with:
      #     secrets: GCP_ASP_BASTION_IP

      - name: Set secrets
        uses: noliran/branch-based-secrets@v1
        with:
          secrets: GCP_SM_BASTION_IP

      # - name: Uplaod data files to Bastion Server
      #   uses: easingthemes/ssh-deploy@main
      #   env:
      #     SSH_PRIVATE_KEY: ${{ secrets.GCP_ASP_BASTION_PEM }}
      #     REMOTE_HOST: ${{ secrets[env.GCP_ASP_BASTION_IP_NAME] }}
      #     REMOTE_USER: somaz
      #     SOURCE: "Convertor/ServerJson/data/"
      #     TARGET: /home/somaz/${{ inputs.environment }}
      #     ARGS: "-rltDvzO --delete"
      #     # ARGS: "-avzr --delete"

      - name: Uplaod data files to Bastion Server
        uses: easingthemes/ssh-deploy@main
        env:
          SSH_PRIVATE_KEY: ${{ secrets.GCP_SM_BASTION_PEM }}
          REMOTE_HOST: ${{ secrets[env.GCP_SM_BASTION_IP_NAME] }}
          REMOTE_USER: somaz
          SOURCE: "Convertor/ServerJson/data/"
          TARGET: /home/somaz/${{ inputs.environment }}-${{ env.PROJECT }}
          ARGS: "-rltDvzO --delete"

      # - name: Uplaod data reload api shell script to Bastion Server
      #   uses: easingthemes/ssh-deploy@main
      #   env:
      #     SSH_PRIVATE_KEY: ${{ secrets.GCP_ASP_BASTION_PEM }}
      #     REMOTE_HOST: ${{ secrets[env.GCP_ASP_BASTION_IP_NAME] }}
      #     REMOTE_USER: somaz
      #     SOURCE: "static_publish.sh"
      #     TARGET: "/home/somaz/"
      #     ARGS: "-rltDvzO --delete"

      - name: Uplaod data reload api shell script to Bastion Server
        uses: easingthemes/ssh-deploy@main
        env:
          SSH_PRIVATE_KEY: ${{ secrets.GCP_SM_BASTION_PEM }}
          REMOTE_HOST: ${{ secrets[env.GCP_SM_BASTION_IP_NAME] }}
          REMOTE_USER: somaz
          SOURCE: "static_publish.sh"
          TARGET: "/home/somaz/"
          ARGS: "-rltDvzO --delete"

  # curl update version and server memory reload api
  update_and_reload:
    needs:
      - upload
      - rsync
    # name: Update version info and Call reload api
    # runs-on: ubuntu-20.04
    # steps:
    #   - name: Set secrets
    #     uses: noliran/branch-based-secrets@v1
    #     with:
    #       secrets: GCP_ASP_DATA_PUBLISH_API_DOMAIN,GCP_ASP_BASTION_IP

    name: Update version info and Call reload api
    runs-on: ubuntu-20.04
    steps:
      - name: Set secrets
        uses: noliran/branch-based-secrets@v1
        with:
          secrets: GCP_ASP_DATA_PUBLISH_API_DOMAIN,GCP_SM_BASTION_IP

      # - name: Curl reload api
      #   uses: appleboy/ssh-action@master
      #   with:
      #     host: ${{ secrets[env.GCP_ASP_BASTION_IP_NAME] }}
      #     port: 22
      #     username: somaz
      #     key: ${{ secrets.GCP_ASP_BASTION_PEM }}
      #     script: |
      #       export GCP_ASP_DATA_PUBLISH_API_DOMAIN_NAME=${{ secrets[env.GCP_ASP_DATA_PUBLISH_API_DOMAIN_NAME] }}
      #       export ASP_DATA_PUBLISH_API_KEY=${{ secrets.ASP_DATA_PUBLISH_API_KEY }}
      #       sh ./static_publish.sh ${{ inputs.modifiedJsonFileNames }}

      - name: Curl reload api
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets[env.GCP_SM_BASTION_IP_NAME] }}
          port: 22
          username: somaz
          key: ${{ secrets.GCP_SM_BASTION_PEM }}
          script: |
            export GCP_ASP_DATA_PUBLISH_API_DOMAIN_NAME=${{ secrets[env.GCP_ASP_DATA_PUBLISH_API_DOMAIN_NAME] }}
            export ASP_DATA_PUBLISH_API_KEY=${{ secrets.ASP_DATA_PUBLISH_API_KEY }}
            sh ./static_publish.sh ${{ inputs.modifiedJsonFileNames }}